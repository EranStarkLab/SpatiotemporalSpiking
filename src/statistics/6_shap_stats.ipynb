{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance analysis \n",
    "### The information computed here is presented in the _Results_ chapter, under the second (_Waveform-based and spike-timing features allow near-perfect classification of PYR and PV cells_) and third (_Transforming multi-channel spike waveforms to event-based delta-like functions removes all waveform-based information and allows extracting purely spatial features_) subsections and in _Tabels 1-3_. It is also presented in _Figure 5_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebooks_constants import SRC_PATH\n",
    "import sys\n",
    "sys.path.insert(0, SRC_PATH)\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "from constants import WAVEFORM, SPIKE_TIMING, SPATIAL, feature_names_org\n",
    "from constants import BEST_WF_CHUNK , BEST_ST_CHUNK, BEST_SPATIAL_CHUNK\n",
    "\n",
    "from paths import MAIN_RES, BASE_RES, FAMS_RES, BASE_FAMS_RES, EVENTS_RES, BASE_EVENTS_RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PATH = MAIN_RES\n",
    "BASE = BASE_RES\n",
    "\n",
    "df = pd.read_csv(PATH, index_col=0)\n",
    " \n",
    "df_base = pd.read_csv(BASE, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_df = df[df.chunk_size == BEST_SPATIAL_CHUNK]\n",
    "spatial_df = spatial_df[spatial_df.modality == 'spatial']\n",
    "\n",
    "spatial_df = spatial_df.dropna(how='all', axis=1)\n",
    "keep = [f'test feature {i+1}' for i in SPATIAL[:-1]]\n",
    "drop = [c for c in spatial_df.columns if c not in keep]\n",
    "spatial_df = spatial_df.drop(columns=drop)\n",
    "\n",
    "mapper = {f'test feature {i+1}': feature_names_org[i] for i in SPATIAL[:-1]}\n",
    "spatial_df = spatial_df.rename(columns=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of test SPD_Count column is  0.00739 [ 0.00583,  0.0132]\n",
      "Median of base SPD_Count column is  0.0011 [ 0.000473,  0.00525]\n",
      "permutation test result for feature SPD_Count is p-value= 0.169\n",
      "\n",
      "Median of test SPD_SD column is  0.00794 [ 0.00612,  0.0105]\n",
      "Median of base SPD_SD column is  0.00289 [ 0.00147,  0.0121]\n",
      "permutation test result for feature SPD_SD is p-value= 0.32\n",
      "\n",
      "Median of test SPD_Area column is  0.0146 [ 0.0108,  0.0194]\n",
      "Median of base SPD_Area column is  0.00289 [ 0.00138,  0.0118]\n",
      "permutation test result for feature SPD_Area is p-value= 0.195\n",
      "\n",
      "Median of test NEG_Time-lag_SS column is  0.0076 [ 0.00649,  0.0104]\n",
      "Median of base NEG_Time-lag_SS column is  0.00268 [ 0.00125,  0.0107]\n",
      "permutation test result for feature NEG_Time-lag_SS is p-value= 0.318\n",
      "\n",
      "Median of test NEG_Time-lag_SD column is  0.0086 [ 0.00733,  0.013]\n",
      "Median of base NEG_Time-lag_SD column is  0.00248 [ 0.00123,  0.0104]\n",
      "permutation test result for feature NEG_Time-lag_SD is p-value= 0.297\n",
      "\n",
      "Median of test FMC_Time-lag_SS column is  0.0943 [ 0.0872,  0.103]\n",
      "Median of base FMC_Time-lag_SS column is  0.0026 [ 0.0013,  0.0104]\n",
      "permutation test result for feature FMC_Time-lag_SS is p-value= 0.000999\n",
      "\n",
      "Median of test FMC_Time-lag_SD column is  0.0928 [ 0.0856,  0.0995]\n",
      "Median of base FMC_Time-lag_SD column is  0.00273 [ 0.00135,  0.0103]\n",
      "permutation test result for feature FMC_Time-lag_SD is p-value= 0.000999\n",
      "\n",
      "Median of test SMC_Time-lag_SS column is  0.0463 [ 0.0382,  0.0514]\n",
      "Median of base SMC_Time-lag_SS column is  0.00279 [ 0.00138,  0.0109]\n",
      "permutation test result for feature SMC_Time-lag_SS is p-value= 0.015\n",
      "\n",
      "Median of test SMC_Time-lag_SD column is  0.0518 [ 0.0458,  0.0628]\n",
      "Median of base SMC_Time-lag_SD column is  0.00273 [ 0.00127,  0.0111]\n",
      "permutation test result for feature SMC_Time-lag_SD is p-value= 0.00599\n",
      "\n",
      "Median of test NEG_Graph_Average_weight column is  0.00705 [ 0.00504,  0.0109]\n",
      "Median of base NEG_Graph_Average_weight column is  0.00258 [ 0.00127,  0.0104]\n",
      "permutation test result for feature NEG_Graph_Average_weight is p-value= 0.313\n",
      "\n",
      "Median of test NEG_Graph_Shortest_path column is  0.00604 [ 0.00434,  0.00818]\n",
      "Median of base NEG_Graph_Shortest_path column is  0.00263 [ 0.00123,  0.0102]\n",
      "permutation test result for feature NEG_Graph_Shortest_path is p-value= 0.33\n",
      "\n",
      "Median of test NEG_Graph_Longest_path column is  0.00582 [ 0.00431,  0.00762]\n",
      "Median of base NEG_Graph_Longest_path column is  0.00251 [ 0.00126,  0.0102]\n",
      "permutation test result for feature NEG_Graph_Longest_path is p-value= 0.331\n",
      "\n",
      "Median of test FMC_Graph_Average_weight column is  0.0381 [ 0.0324,  0.0506]\n",
      "Median of base FMC_Graph_Average_weight column is  0.00267 [ 0.00136,  0.0104]\n",
      "permutation test result for feature FMC_Graph_Average_weight is p-value= 0.027\n",
      "\n",
      "Median of test FMC_Graph_Shortest_path column is  0.0675 [ 0.0617,  0.0773]\n",
      "Median of base FMC_Graph_Shortest_path column is  0.00251 [ 0.00121,  0.0101]\n",
      "permutation test result for feature FMC_Graph_Shortest_path is p-value= 0.000999\n",
      "\n",
      "Median of test FMC_Graph_Longest_path column is  0.0138 [ 0.0108,  0.0191]\n",
      "Median of base FMC_Graph_Longest_path column is  0.00255 [ 0.00128,  0.0103]\n",
      "permutation test result for feature FMC_Graph_Longest_path is p-value= 0.182\n",
      "\n",
      "Median of test SMC_Graph_Average_weight column is  0.00814 [ 0.00667,  0.00991]\n",
      "Median of base SMC_Graph_Average_weight column is  0.00257 [ 0.00126,  0.0109]\n",
      "permutation test result for feature SMC_Graph_Average_weight is p-value= 0.308\n",
      "\n",
      "Median of test SMC_Graph_Shortest_path column is  0.00799 [ 0.00622,  0.0114]\n",
      "Median of base SMC_Graph_Shortest_path column is  0.00276 [ 0.00128,  0.0104]\n",
      "permutation test result for feature SMC_Graph_Shortest_path is p-value= 0.302\n",
      "\n",
      "Median of test SMC_Graph_Longest_path column is  0.0129 [ 0.0101,  0.0156]\n",
      "Median of base SMC_Graph_Longest_path column is  0.0026 [ 0.0013,  0.0106]\n",
      "permutation test result for feature SMC_Graph_Longest_path is p-value= 0.207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spatial_df_base = df_base[df_base.chunk_size == BEST_SPATIAL_CHUNK]\n",
    "spatial_df_base = spatial_df_base[spatial_df_base.modality == 'spatial']\n",
    "\n",
    "keep = [f'test feature {i+1}' for i in SPATIAL[:-1]]\n",
    "drop = [c for c in spatial_df_base.columns if c not in keep]\n",
    "\n",
    "spatial_df_base = spatial_df_base.drop(columns=drop)\n",
    "spatial_df_base = spatial_df_base.dropna(how='all', axis=1)\n",
    "spatial_df_base = spatial_df_base.rename(columns=mapper)\n",
    "\n",
    "for col in spatial_df.columns:\n",
    "    col_test = spatial_df[col].to_numpy()\n",
    "    col_base = spatial_df_base[col].to_numpy()\n",
    "    \n",
    "    test_median, test_prec25, test_prec75 = np.percentile(col_test, [50, 25, 75])\n",
    "    base_median, base_prec25, base_prec75 = np.percentile(col_base, [50, 25, 75])\n",
    "    \n",
    "    print(f\"Median of test {col} column is {test_median: .3g} [{test_prec25: .3g}, {test_prec75: .3g}]\")\n",
    "    print(f\"Median of base {col} column is {base_median: .3g} [{base_prec25: .3g}, {base_prec75: .3g}]\")\n",
    "    \n",
    "    p_val = (1 + (col_base > np.median(col_test)).sum()) / (1 + len(col_base))\n",
    "    print(f\"permutation test result for feature {col} is p-value={p_val: .3g}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_df = df[df.chunk_size == BEST_ST_CHUNK]\n",
    "st_df = st_df[st_df.modality == 'spike-timing']\n",
    "\n",
    "st_df = st_df.dropna(how='all', axis=1)\n",
    "keep = [f'test feature {i+1}' for i in SPIKE_TIMING[:-1]]\n",
    "drop = [c for c in st_df.columns if c not in keep]\n",
    "st_df = st_df.drop(columns=drop)\n",
    "mapper = {f'test feature {i+1}': feature_names_org[i] for i in SPIKE_TIMING[:-1]}\n",
    "st_df = st_df.rename(columns=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of test Firing_rate column is  0.0766 [ 0.063,  0.0894]\n",
      "Median of base Firing_rate column is  0.0182 [ 0.0102,  0.0302]\n",
      "permutation test result for feature Firing_rate is p-value= 0.038\n",
      "\n",
      "Median of test D_KL_short column is  0.0255 [ 0.0206,  0.0352]\n",
      "Median of base D_KL_short column is  0.0183 [ 0.0104,  0.0337]\n",
      "permutation test result for feature D_KL_short is p-value= 0.359\n",
      "\n",
      "Median of test D_KL_long column is  0.187 [ 0.172,  0.199]\n",
      "Median of base D_KL_long column is  0.0181 [ 0.00972,  0.0311]\n",
      "permutation test result for feature D_KL_long is p-value= 0.000999\n",
      "\n",
      "Median of test Jump_index column is  0.0291 [ 0.0261,  0.0324]\n",
      "Median of base Jump_index column is  0.0187 [ 0.0105,  0.0335]\n",
      "permutation test result for feature Jump_index is p-value= 0.311\n",
      "\n",
      "Median of test PSD_center column is  0.0164 [ 0.0129,  0.0195]\n",
      "Median of base PSD_center column is  0.0194 [ 0.011,  0.0329]\n",
      "permutation test result for feature PSD_center is p-value= 0.561\n",
      "\n",
      "Median of test PSD'_center column is  0.00902 [ 0.00691,  0.0109]\n",
      "Median of base PSD'_center column is  0.0202 [ 0.0114,  0.0345]\n",
      "permutation test result for feature PSD'_center is p-value= 0.833\n",
      "\n",
      "Median of test Rise_time column is  0.0306 [ 0.0263,  0.0353]\n",
      "Median of base Rise_time column is  0.0163 [ 0.00972,  0.0305]\n",
      "permutation test result for feature Rise_time is p-value= 0.249\n",
      "\n",
      "Median of test Uniform_distance column is  0.135 [ 0.118,  0.157]\n",
      "Median of base Uniform_distance column is  0.0185 [ 0.0105,  0.0315]\n",
      "permutation test result for feature Uniform_distance is p-value= 0.002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st_df_base = df_base[df_base.chunk_size == BEST_ST_CHUNK]\n",
    "st_df_base = st_df_base[st_df_base.modality == 'spike-timing']\n",
    "\n",
    "st_df_base = st_df_base.dropna(how='all', axis=1)\n",
    "st_df_base = st_df_base.drop(columns=drop)\n",
    "st_df_base = st_df_base.rename(columns=mapper)\n",
    "\n",
    "for col in st_df.columns:\n",
    "    col_test = st_df[col].to_numpy()\n",
    "    col_base = st_df_base[col].to_numpy()\n",
    "    \n",
    "    test_median, test_prec25, test_prec75 = np.percentile(col_test, [50, 25, 75])\n",
    "    base_median, base_prec25, base_prec75 = np.percentile(col_base, [50, 25, 75])\n",
    "    \n",
    "    print(f\"Median of test {col} column is {test_median: .3g} [{test_prec25: .3g}, {test_prec75: .3g}]\")\n",
    "    print(f\"Median of base {col} column is {base_median: .3g} [{base_prec25: .3g}, {base_prec75: .3g}]\")\n",
    "    \n",
    "    p_val = (1 + (col_base > np.median(col_test)).sum()) / (1 + len(col_base))\n",
    "    print(f\"permutation test result for feature {col} is p-value={p_val: .3g}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_df = df[df.chunk_size == BEST_WF_CHUNK]\n",
    "wf_df = wf_df[wf_df.modality == 'waveform']\n",
    "\n",
    "wf_df = wf_df.dropna(how='all', axis=1)\n",
    "keep = [f'test feature {i+1}' for i in WAVEFORM[:-1]]\n",
    "drop = [c for c in wf_df.columns if c not in keep]\n",
    "wf_df = wf_df.drop(columns=drop)\n",
    "mapper = {f'test feature {i+1}': feature_names_org[i] for i in WAVEFORM[:-1]}\n",
    "wf_df = wf_df.rename(columns=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of test Break_measure column is  0.00284 [ 0.00201,  0.00425]\n",
      "Median of base Break_measure column is  0.00924 [ 0.00406,  0.0253]\n",
      "permutation test result for feature Break_measure is p-value= 0.838\n",
      "\n",
      "Median of test FWHM column is  0.00483 [ 0.00357,  0.00748]\n",
      "Median of base FWHM column is  0.00651 [ 0.00276,  0.0177]\n",
      "permutation test result for feature FWHM is p-value= 0.587\n",
      "\n",
      "Median of test Acceleration column is  0.117 [ 0.0993,  0.154]\n",
      "Median of base Acceleration column is  0.00913 [ 0.00398,  0.0243]\n",
      "permutation test result for feature Acceleration is p-value= 0.002\n",
      "\n",
      "Median of test Max_speed column is  0.0109 [ 0.00661,  0.014]\n",
      "Median of base Max_speed column is  0.00742 [ 0.00326,  0.0196]\n",
      "permutation test result for feature Max_speed is p-value= 0.415\n",
      "\n",
      "Median of test TTP_magnitude column is  0.109 [ 0.0828,  0.121]\n",
      "Median of base TTP_magnitude column is  0.0101 [ 0.00429,  0.0256]\n",
      "permutation test result for feature TTP_magnitude is p-value= 0.003\n",
      "\n",
      "Median of test TTP_duration column is  0.248 [ 0.231,  0.261]\n",
      "Median of base TTP_duration column is  0.0071 [ 0.003,  0.0194]\n",
      "permutation test result for feature TTP_duration is p-value= 0.000999\n",
      "\n",
      "Median of test Rise_coefficient column is  0.00481 [ 0.00359,  0.0081]\n",
      "Median of base Rise_coefficient column is  0.00702 [ 0.00302,  0.0183]\n",
      "permutation test result for feature Rise_coefficient is p-value= 0.618\n",
      "\n",
      "Median of test Smile_cry column is  0.0131 [ 0.0107,  0.0153]\n",
      "Median of base Smile_cry column is  0.00906 [ 0.00394,  0.0248]\n",
      "permutation test result for feature Smile_cry is p-value= 0.423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wf_df_base = df_base[df_base.chunk_size == BEST_WF_CHUNK]\n",
    "wf_df_base = wf_df_base[wf_df_base.modality == 'waveform']\n",
    "\n",
    "wf_df_base = wf_df_base.dropna(how='all', axis=1)\n",
    "wf_df_base = wf_df_base.drop(columns=drop)\n",
    "wf_df_base = wf_df_base.rename(columns=mapper)\n",
    "\n",
    "for col in wf_df.columns:\n",
    "    col_test = wf_df[col].to_numpy()\n",
    "    col_base = wf_df_base[col].to_numpy()\n",
    "    \n",
    "    test_median, test_prec25, test_prec75 = np.percentile(col_test, [50, 25, 75])\n",
    "    base_median, base_prec25, base_prec75 = np.percentile(col_base, [50, 25, 75])\n",
    "    \n",
    "    print(f\"Median of test {col} column is {test_median: .3g} [{test_prec25: .3g}, {test_prec75: .3g}]\")\n",
    "    print(f\"Median of base {col} column is {base_median: .3g} [{base_prec25: .3g}, {base_prec75: .3g}]\")\n",
    "    \n",
    "    p_val = (1 + (col_base > np.median(col_test)).sum()) / (1 + len(col_base))\n",
    "    print(f\"permutation test result for feature {col} is p-value={p_val: .3g}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = EVENTS_RES\n",
    "BASE = BASE_EVENTS_RES\n",
    "\n",
    "df = pd.read_csv(PATH, index_col=0)\n",
    " \n",
    "df_base = pd.read_csv(BASE, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_names = ['FMC', 'NEG', 'SMC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = df[df.chunk_size == BEST_SPATIAL_CHUNK]\n",
    "\n",
    "keep = [f'test feature {i+1}' for i in np.arange(len(events_names))]\n",
    "drop = [c for c in events_df.columns if c not in keep]\n",
    "events_df = events_df.drop(columns=drop)\n",
    "\n",
    "mapper = {f'test feature {i+1}': events_names[i] for i in np.arange(len(events_names))}\n",
    "events_df = events_df.rename(columns=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of test FMC column is  0.264 [ 0.249,  0.29]\n",
      "Median of base FMC column is  0.00913 [ 0.00464,  0.0372]\n",
      "permutation test result for feature FMC is p-value= 0.000999\n",
      "\n",
      "Median of test NEG column is  0.0284 [ 0.0236,  0.0361]\n",
      "Median of base NEG column is  0.00844 [ 0.00452,  0.036]\n",
      "permutation test result for feature NEG is p-value= 0.297\n",
      "\n",
      "Median of test SMC column is  0.0983 [ 0.0881,  0.113]\n",
      "Median of base SMC column is  0.00908 [ 0.0047,  0.0389]\n",
      "permutation test result for feature SMC is p-value= 0.112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events_df_base = df_base[df_base.chunk_size == 25]\n",
    "\n",
    "events_df_base = events_df_base.drop(columns=drop)\n",
    "events_df_base = events_df_base.dropna(how='all', axis=1)\n",
    "events_df_base = events_df_base.rename(columns=mapper)\n",
    "\n",
    "for col in events_df.columns:\n",
    "    col_test = events_df[col].to_numpy()\n",
    "    col_base = events_df_base[col].to_numpy()\n",
    "    \n",
    "    test_median, test_prec25, test_prec75 = np.percentile(col_test, [50, 25, 75])\n",
    "    base_median, base_prec25, base_prec75 = np.percentile(col_base, [50, 25, 75])\n",
    "    \n",
    "    print(f\"Median of test {col} column is {test_median: .3g} [{test_prec25: .3g}, {test_prec75: .3g}]\")\n",
    "    print(f\"Median of base {col} column is {base_median: .3g} [{base_prec25: .3g}, {base_prec75: .3g}]\")\n",
    "    \n",
    "    p_val = (1 + (col_base > np.median(col_test)).sum()) / (1 + len(col_base))\n",
    "    print(f\"permutation test result for feature {col} is p-value={p_val: .3g}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = FAMS_RES\n",
    "BASE = BASE_FAMS_RES\n",
    "\n",
    "df = pd.read_csv(PATH, index_col=0)\n",
    "\n",
    "df = pd.read_csv(PATH, index_col=0)\n",
    " \n",
    "df_base = pd.read_csv(BASE, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "familiy_names = ['value-based', 'time-based', 'graph-based']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_df = df[df.chunk_size == BEST_SPATIAL_CHUNK]\n",
    "\n",
    "keep = [f'test feature {i+1}' for i in np.arange(len(familiy_names))]\n",
    "drop = [c for c in family_df.columns if c not in keep]\n",
    "family_df = family_df.drop(columns=drop)\n",
    "\n",
    "mapper = {f'test feature {i+1}': familiy_names[i] for i in np.arange(len(familiy_names))}\n",
    "family_df = family_df.rename(columns=mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of test value-based column is  0.0281 [ 0.0208,  0.0361]\n",
      "Median of base value-based column is  0.00556 [ 0.00293,  0.0225]\n",
      "permutation test result for feature value-based is p-value= 0.191\n",
      "\n",
      "Median of test time-based column is  0.246 [ 0.229,  0.267]\n",
      "Median of base time-based column is  0.0104 [ 0.00544,  0.0435]\n",
      "permutation test result for feature time-based is p-value= 0.000999\n",
      "\n",
      "Median of test graph-based column is  0.111 [ 0.102,  0.129]\n",
      "Median of base graph-based column is  0.0134 [ 0.0071,  0.0625]\n",
      "permutation test result for feature graph-based is p-value= 0.135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "family_df_base = df_base[df_base.chunk_size == BEST_SPATIAL_CHUNK]\n",
    "\n",
    "family_df_base = family_df_base.drop(columns=drop)\n",
    "family_df_base = family_df_base.dropna(how='all', axis=1)\n",
    "family_df_base = family_df_base.rename(columns=mapper)\n",
    "\n",
    "for col in family_df.columns:\n",
    "    col_test = family_df[col].to_numpy()\n",
    "    col_base = family_df_base[col].to_numpy()\n",
    "    \n",
    "    test_median, test_prec25, test_prec75 = np.percentile(col_test, [50, 25, 75])\n",
    "    base_median, base_prec25, base_prec75 = np.percentile(col_base, [50, 25, 75])\n",
    "    \n",
    "    print(f\"Median of test {col} column is {test_median: .3g} [{test_prec25: .3g}, {test_prec75: .3g}]\")\n",
    "    print(f\"Median of base {col} column is {base_median: .3g} [{base_prec25: .3g}, {base_prec75: .3g}]\")\n",
    "    \n",
    "    p_val = (1 + (col_base > np.median(col_test)).sum()) / (1 + len(col_base))\n",
    "    print(f\"permutation test result for feature {col} is p-value={p_val: .3g}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional statistical comparisons applying the Kruskal-Wallis test were conducted in Matlab. Those were simply executed for each spatial feature family, and for each spatial event group. To perform the comparisons in Matlab use: \n",
    "[p, tbl, stats] = kruskalwallis(mat)\n",
    "\n",
    "c = multcompare(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
